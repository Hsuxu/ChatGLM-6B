{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json5\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset, Dataset\n",
    "from collections import Counter\n",
    "from collections import Counter\n",
    "from joblib import Parallel,delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_xlsx = '/mnt/users/LLMa/ChatGLM-6B/data/LUNG/origin_chest_ct_report_pid_reformat.csv'\n",
    "percentile = 0.15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get report to conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df = pd.read_csv(origin_xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544570\n",
      "529963\n"
     ]
    }
   ],
   "source": [
    "print(len(origin_df))\n",
    "origin_df['report_evidences'].replace('', np.nan, inplace=True)\n",
    "origin_df.dropna(subset=['report_evidences'], inplace=True)\n",
    "\n",
    "origin_df['report_conclusion'].replace('', np.nan, inplace=True)\n",
    "origin_df.dropna(subset=['report_conclusion'], inplace=True)\n",
    "\n",
    "origin_df['report_conclusion'].replace('id:0', np.nan, inplace=True)\n",
    "origin_df.dropna(subset=['report_conclusion'], inplace=True)\n",
    "print(len(origin_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df.replace('\\s+', '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392498 333624 58874\n"
     ]
    }
   ],
   "source": [
    "pid_set = list(set(list(origin_df['pid'])))\n",
    "train_pids = pid_set[int(len(pid_set)*percentile):]\n",
    "val_pids = pid_set[:int(len(pid_set)*percentile)]\n",
    "print(len(pid_set), len(train_pids), len(val_pids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(list(origin_df['pid']))\n",
    "his_pids = []\n",
    "for pid,c in counter.items():\n",
    "    if c>1:\n",
    "        his_pids.append(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_to_report(rows_df):\n",
    "    reg = r'(((20)[1-2][0-9])((0[1-9]|1[0-2]))((0[1-9]|1[0-9])|2[0-9]|3[0-1]))'\n",
    "    reg2 = r'(\\.|\\/|-|年)(([1-9](\\.|\\/|-)[1-9])|(\\d{2}(\\.|\\/|-|月)[1-9])|([1-9](\\.|\\/|-)\\d{2})|(\\d{2}(\\.|\\/|-|月)\\d{2}))(\\D)'\n",
    "    reg3 = r'(((20)[1-2][0-9])-((0[1-9]|1[0-2]))-((0[1-9]|1[0-9])|2[0-9]|3[0-1]))'\n",
    "    date_strs=['']*len(rows_df)\n",
    "    i=0\n",
    "    for idx, row in rows_df.iterrows():\n",
    "        # get current date\n",
    "        study_instance_uid = row['study_instance_uid']\n",
    "        compose_str = ''.join(study_instance_uid.split('.'))\n",
    "        r1 = None\n",
    "        r1= re.finditer(reg, study_instance_uid)\n",
    "        for r in r1:\n",
    "            date = r.group()\n",
    "#             print(date)\n",
    "            try:\n",
    "                date = '{}{:02d}{}'.format(date[:4],int(date[4:-2]),str(date[-2:]))\n",
    "                date =datetime.strptime(date, '%Y-%m-%d')\n",
    "                date_str = '报告时间: {}。'.format(date)\n",
    "                new_report = date_str+row['report_evidences']\n",
    "                rows_df.at[idx, 'report_evidences'] = new_report\n",
    "                rows_df.at[idx, 'date'] =str(date)\n",
    "            except:\n",
    "                pass\n",
    "        if len(list(r1))==0:\n",
    "            for t in study_instance_uid.split('.'):\n",
    "                if len(t)==10:\n",
    "                    loc_t = time.localtime(int(float(t)))\n",
    "                    dt = time.strftime(\"%Y-%m-%d\",loc_t)\n",
    "                    date_str = '报告时间: {}。'.format(dt)\n",
    "                    new_report = date_str+row['report_evidences']\n",
    "                    rows_df.at[idx, 'report_evidences'] = new_report\n",
    "                    rows_df.at[idx, 'date'] = dt\n",
    "        \n",
    "        # get previous date\n",
    "        conculsion = row['report_conclusion']\n",
    "        \n",
    "        r2 = None\n",
    "        r2= re.finditer(reg2, conculsion)\n",
    "        for r_item in r2:\n",
    "            date = r_item.group()[:-1]\n",
    "            date_split = re.split('\\.|-|\\/|年|月',date)\n",
    "            for i,item in enumerate(date_split):\n",
    "                if len(item)==0:\n",
    "                    continue\n",
    "                try:\n",
    "                    item = '{:02d}'.format(int(float(item)))\n",
    "                except:\n",
    "                    print(date)\n",
    "                date_split[i]=item\n",
    "            new_date = '-'.join(date_split)\n",
    "            conculsion = conculsion.replace(date,new_date)\n",
    "            rows_df.at[idx,'report_conclusion']=conculsion\n",
    "        r3 = None\n",
    "        r3 = re.search(reg3,conculsion)\n",
    "        if r3 is not None:\n",
    "            s,e = r3.span()\n",
    "            pre_date = conculsion[s:e]\n",
    "            rows_df.at[idx,'pervious_date']=pre_date\n",
    "    return rows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "origin_df_with_date = add_date_to_report(origin_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single(pid,origin_df_with_date):\n",
    "    sel_df = origin_df_with_date.query('pid==\"{}\"'.format(pid))\n",
    "    if len(sel_df)>1:\n",
    "        sel_df=sel_df.sort_values(by='date')\n",
    "    line = 0\n",
    "    train_pair = []\n",
    "    for idx,row in sel_df.iterrows():\n",
    "        pre_date=row['pervious_date']\n",
    "        date = str(row['date'])\n",
    "        evidence = row['report_evidences']\n",
    "        conlusion = row['report_conclusion']\n",
    "        \n",
    "        pre_row = sel_df.query('date==\"{}\"'.format(pre_date))\n",
    "        history = ''\n",
    "        if len(pre_row)!=0:\n",
    "            history = list(pre_row['report_evidences'])[0]\n",
    "        train_pair.append([pid,evidence,conlusion,history,date,pre_date])\n",
    "    return train_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▊                                                               | 15903/83496 [05:51<25:31, 44.14it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 77%|████████████████████████████████████████████████████████████▏                 | 64423/83496 [23:03<06:41, 47.48it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_res = []\n",
    "for pid in tqdm(his_pids):\n",
    "    train_res+= process_single(pid,origin_df_with_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77186bcf6a304ce9a425423da368fe2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/221 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "142981614"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(data=train_res,columns=['pid','Input','Output','History','Date','Pre_Date'])\n",
    "train_data = Dataset.from_pandas(train_df)\n",
    "train_data.to_json('/mnt/users/LLMa/ChatGLM-6B/data/LUNG/train_conclusion_history.json',force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 58874/58874 [16:55<00:00, 57.99it/s]\n"
     ]
    }
   ],
   "source": [
    "val_res = []\n",
    "for pid in tqdm(val_pids):\n",
    "    val_res+= proces_single(pid,origin_df_with_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame(data=val_res,columns=['Input','Output','History'])\n",
    "val_data = Dataset.from_pandas(val_df)\n",
    "val_data.to_json('/mnt/users/LLMa/ChatGLM-6B/data/LUNG/val_conclusion_history.json',force_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
